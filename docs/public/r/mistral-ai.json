{
  "name": "mistral-ai",
  "type": "registry:block",
  "title": "Mistral AI",
  "description": "Use Mistral AI models for fast and efficient text generation",
  "registryDependencies": [],
  "dependencies": ["@vercel/workflow"],
  "files": [
    {
      "path": "registry/steps/mistral-ai.tsx",
      "type": "registry:component",
      "content": "import { FatalError } from 'workflow';\n\ntype MistralParams = {\n  messages: { role: string; content: string }[];\n  model?: string;\n  temperature?: number;\n};\n\nexport async function mistralAI(params: MistralParams) {\n  'use step';\n\n  const apiKey = process.env.MISTRAL_API_KEY;\n\n  if (!apiKey) {\n    throw new FatalError('MISTRAL_API_KEY is required');\n  }\n\n  const response = await fetch('https://api.mistral.ai/v1/chat/completions', {\n    method: 'POST',\n    headers: {\n      Authorization: `Bearer ${apiKey}`,\n      'Content-Type': 'application/json',\n    },\n    body: JSON.stringify({\n      model: params.model || 'mistral-large-latest',\n      messages: params.messages,\n      temperature: params.temperature || 0.7,\n    }),\n  });\n\n  if (!response.ok) {\n    throw new FatalError(`Mistral API error: ${response.status}`);\n  }\n\n  const data = await response.json();\n  return data.choices[0].message.content;\n}\n",
      "target": "components/steps/mistral-ai.tsx"
    }
  ],
  "envVars": {
    "MISTRAL_API_KEY": ""
  }
}
