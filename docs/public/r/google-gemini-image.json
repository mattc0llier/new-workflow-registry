{
  "name": "google-gemini-image",
  "type": "registry:block",
  "title": "Google Gemini Image",
  "description": "Generate images from text using Google Gemini (Nano Banana)",
  "registryDependencies": [],
  "dependencies": ["@vercel/workflow"],
  "files": [
    {
      "path": "registry/steps/google-gemini-image.tsx",
      "type": "registry:component",
      "content": "import { FatalError } from 'workflow';\n\ntype GeminiImageParams = {\n  prompt: string;\n  model?: string;\n};\n\nexport async function googleGeminiImage(params: GeminiImageParams) {\n  'use step';\n\n  const apiKey = process.env.GOOGLE_AI_API_KEY;\n\n  if (!apiKey) {\n    throw new FatalError('GOOGLE_AI_API_KEY is required');\n  }\n\n  const model = params.model || 'gemini-2.5-flash-image';\n  const response = await fetch(\n    `https://generativelanguage.googleapis.com/v1beta/models/${model}:generateContent?key=${apiKey}`,\n    {\n      method: 'POST',\n      headers: {\n        'Content-Type': 'application/json',\n      },\n      body: JSON.stringify({\n        contents: [\n          {\n            parts: [{ text: params.prompt }],\n          },\n        ],\n      }),\n    }\n  );\n\n  if (!response.ok) {\n    throw new FatalError(`Google AI API error: ${response.status}`);\n  }\n\n  const data = await response.json();\n\n  // Extract the image data from the response\n  let imageBase64: string | null = null;\n  let textResponse: string | null = null;\n\n  for (const candidate of data.candidates || []) {\n    for (const part of candidate.content?.parts || []) {\n      if (part.text) {\n        textResponse = part.text;\n      } else if (part.inlineData) {\n        imageBase64 = part.inlineData.data;\n      }\n    }\n  }\n\n  if (!imageBase64) {\n    throw new FatalError('No image data returned from Google AI');\n  }\n\n  return {\n    image: imageBase64,\n    text: textResponse,\n    mimeType: 'image/png',\n  };\n}\n",
      "target": "components/steps/google-gemini-image.tsx"
    }
  ],
  "envVars": {
    "GOOGLE_AI_API_KEY": ""
  }
}
