{
  "name": "google-gemini",
  "type": "registry:block",
  "title": "Google Gemini",
  "description": "Generate content using Google Gemini AI models",
  "registryDependencies": [],
  "dependencies": ["@vercel/workflow"],
  "files": [
    {
      "path": "registry/steps/google-gemini.tsx",
      "type": "registry:component",
      "content": "import { fatalError } from '@vercel/workflow';\n\ntype GeminiParams = {\n  prompt: string;\n  model?: string;\n  temperature?: number;\n};\n\nexport async function googleGemini(params: GeminiParams) {\n  \"use step\";\n\n  const apiKey = process.env.GOOGLE_AI_API_KEY;\n\n    if (!apiKey) {\n      throw fatalError('GOOGLE_AI_API_KEY is required');\n    }\n\n    const model = params.model || 'gemini-1.5-pro';\n    const response = await fetch(\n      \\`https://generativelanguage.googleapis.com/v1beta/models/\\${model}:generateContent?key=\\${apiKey}\\`,\n      {\n        method: 'POST',\n        headers: {\n          'Content-Type': 'application/json',\n        },\n        body: JSON.stringify({\n          contents: [{\n            parts: [{ text: params.prompt }]\n          }],\n          generationConfig: {\n            temperature: params.temperature || 0.7,\n          },\n        }),\n      }\n    );\n\n    if (!response.ok) {\n      throw fatalError(\\`Google AI API error: \\${response.status}\\`);\n    }\n\n    const data = await response.json();\n    return data.candidates[0].content.parts[0].text;\n}",
      "target": "components/steps/google-gemini.tsx"
    }
  ]
}
