{
  "name": "runpod-inference",
  "type": "registry:block",
  "title": "RunPod GPU Inference",
  "description": "Run AI models on RunPod serverless GPUs",
  "registryDependencies": [],
  "dependencies": ["@vercel/workflow"],
  "files": [
    {
      "path": "registry/steps/runpod-inference.tsx",
      "type": "registry:component",
      "content": "import { FatalError } from 'workflow';\n\ntype RunPodParams = {\n  endpoint_id: string;\n  input: Record<string, any>;\n};\n\nexport async function runpodInference(params: RunPodParams) {\n  'use step';\n\n  const apiKey = process.env.RUNPOD_API_KEY;\n\n  if (!apiKey) {\n    throw new FatalError('RUNPOD_API_KEY is required');\n  }\n\n  const response = await fetch(\n    `https://api.runpod.ai/v2/${params.endpoint_id}/run`,\n    {\n      method: 'POST',\n      headers: {\n        Authorization: `Bearer ${apiKey}`,\n        'Content-Type': 'application/json',\n      },\n      body: JSON.stringify({\n        input: params.input,\n      }),\n    }\n  );\n\n  if (!response.ok) {\n    throw new FatalError(`RunPod API error: ${response.status}`);\n  }\n\n  return await response.json();\n}\n",
      "target": "components/steps/runpod-inference.tsx"
    }
  ],
  "envVars": {
    "RUNPOD_API_KEY": ""
  }
}
