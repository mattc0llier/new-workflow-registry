{
  "name": "openai-chat",
  "type": "registry:block",
  "title": "OpenAI Chat Completion",
  "description": "Generate chat completions using OpenAI GPT models",
  "registryDependencies": [],
  "dependencies": ["@vercel/workflow"],
  "files": [
    {
      "path": "registry/steps/openai-chat.tsx",
      "type": "registry:component",
      "content": "import { fatalError } from '@vercel/workflow';\n\ntype ChatParams = {\n  messages: { role: string; content: string }[];\n  model?: string;\n  temperature?: number;\n};\n\nexport async function openaiChat(params: ChatParams) {\n  \"use step\";\n\n  const apiKey = process.env.OPENAI_API_KEY;\n\n    if (!apiKey) {\n      throw fatalError('OPENAI_API_KEY is required');\n    }\n\n    const response = await fetch('https://api.openai.com/v1/chat/completions', {\n      method: 'POST',\n      headers: {\n        'Authorization': `Bearer ${apiKey}`,\n        'Content-Type': 'application/json',\n      },\n      body: JSON.stringify({\n        model: params.model || 'gpt-4',\n        messages: params.messages,\n        temperature: params.temperature || 0.7,\n      }),\n    });\n\n    if (!response.ok) {\n      throw fatalError(`OpenAI API error: ${response.status}`);\n    }\n\n    const data = await response.json();\n    return data.choices[0].message.content;\n}\n\n",
      "target": "components/steps/openai-chat.tsx"
    }
  ]
}
